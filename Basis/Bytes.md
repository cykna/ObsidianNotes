When starting to work with computers, we must understand how data is structured.
The way data is structured is called bytes. It's a sequence of 8 bits. Where a bit is actually named as 'binary digit'. The value of a bit is either 0 or 1, on the physics, it's when a transistor is 'activated', if so, it's 1, if not is 0. The group of 8 bits is called a byte.
In programming, in reality everything is an abstraction to what a byte is. For example, [[Instruction|instructions]] are simply bytes that a processor understands and based on so executes some instruction. [[String|strings]] are in fact an [[Array|array]] of bytes where each byte represents a char, or, depending of the [[Encoding]] of so, a group of bytes represent a char. Same thing for numbers. When working with [[Int|int]] in C for example, the 'int' type is actually a '4 byte signed integer'.
A [[Pointer|pointer]] is in 64 bit architecture, 8 bytes, and in 32 bit architecture 4 bytes, the same size as an [[usize]]. [[Objects|Objects]], supposing [[OOP]] are just pointers to the [[Heap]] that actually contain the information about the object, which is a contiguous byte array that interprets the bytes in a order.
The primitives, in case, the types that are more close to bytes than any others are numbers. The reason is very simple actually: they're simple bytes that are interpreted a way we can understand.
When we print a number on the console for example, let's say we get '5', actually what happened is that the bits of the number are 101 and we converted it to it's [[Ascii|ascii]] equivalent. Simple as that.
In programming we have a lot of types of numbers. In languages like [[Javascript]] or [[Python]] or other high level ones we generally use a single type for everything. In rust for example we got i8, i16, i32, i64, i128 which are signed integers followed by the amount of bits each use. The same logic for 'u' variants: u8, u16, u32, u64, u128. Rust follows IEEE-752 for implementing floats, or decimal values, and it contains f32 and f64, equivalents to 'float' and 'double' in C. Actually, the only type that Javascript supports is f64 if not using typed arrays.